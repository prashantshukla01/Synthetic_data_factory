# ğŸš€ GenFactory
### Autonomous Synthetic Data Pipeline & Model Fine-Tuning Framework

GenFactory is an end-to-end, production-grade framework for **synthetic data generation and model distillation** using a **Teacherâ€“Student architecture**.

The system leverages **Gemini (Teacher models)** to autonomously generate and evaluate high-quality, domain-specific datasets via a **self-healing LangGraph orchestration loop**, and then fine-tunes a lightweight **Phi-3 (Student model)** for efficient deployment in niche domains such as **Python automation**, **FinTech security**, and other specialized technical areas.

This project is designed with **industry-grade reliability, observability, and scalability** in mind.

---

## âœ¨ Key Features

### ğŸ§  Autonomous Orchestration
- LangGraph-powered stateful workflow
- Generator â†’ Judge â†’ Retry â†’ Accept execution loop
- Automatic retry handling and failure recovery

### ğŸ›¡ï¸ Self-Healing Data Quality
- Dedicated **Judge LLM (Gemini 1.5 Flash)**
- Multi-metric evaluation (relevance, correctness, clarity)
- Only samples scoring **â‰¥ 8/10** are accepted
- Controlled retry logic for weak outputs

### ğŸ’¾ Persistent Memory & Crash Safety
- **Redis Stack**â€“based checkpointing (RedisJSON + RediSearch)
- Safe resume for long-running generation jobs
- Durable state storage across batches

### ğŸ§ª Hardware-Aware Fine-Tuning
- Apple Silicon (M3) optimized via **MPS + FP16**
- NVIDIA cluster training via **QLoRA + bf16**
- Separate pipelines for laptop and supercomputer training

### ğŸ“Š Industry-Level Observability
- Full tracing with **LangSmith**
- Inspect every LLM decision and graph transition
- Cost, retry, and quality visibility

---

## ğŸ—ï¸ Technical Architecture

The system is structured into **four industrial layers**, each with a single responsibility:

### Level 1 â€” Orchestration Brain
**LangGraph + Redis Stack**
- Stateful control flow
- Conditional routing and retries
- Crash-safe checkpointing

### Level 2 â€” Data Engineering
**JSONL Sink + Hugging Face Hub**
- Deterministic formatting
- Incremental dataset construction
- Automated versioned publishing

### Level 3 â€” Domain Training
**SFT + LoRA / QLoRA**
- Phi-3 fine-tuning
- Hardware-specific optimization paths

### Level 4 â€” Evaluation Loop
**Accuracy Gain Benchmarking**
- Base vs fine-tuned model comparison
- Promotion gating
- Regression detection

---

## ğŸ“‚ Project Structure

```text
synthetic_data_factory/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ graph/                  # LangGraph orchestration
â”‚   â”‚   â”œâ”€â”€ state.py             # State schema (retry_count, score, etc.)
â”‚   â”‚   â”œâ”€â”€ nodes.py             # Gemini Generator & Judge logic
â”‚   â”‚   â”œâ”€â”€ edges.py             # Conditional routing rules
â”‚   â”‚   â””â”€â”€ workflow.py          # Compiled LangGraph + Redis Saver
â”‚   â”‚
â”‚   â”œâ”€â”€ data_eng/               # Data engineering layer
â”‚   â”‚   â”œâ”€â”€ formatter.py         # JSONL / ChatML standardization
â”‚   â”‚   â””â”€â”€ hf_uploader.py       # Hugging Face dataset sync
â”‚   â”‚
â”‚   â”œâ”€â”€ training/               # Fine-tuning pipelines
â”‚   â”‚   â”œâ”€â”€ train_laptop.py      # Apple Silicon (M3, MPS, FP16)
â”‚   â”‚   â””â”€â”€ train_super.py       # NVIDIA A100 (CUDA, QLoRA, bf16)
â”‚   â”‚
â”‚   â””â”€â”€ main.py                 # Synthetic data factory entry point
â”‚
â”œâ”€â”€ .env                        # Secrets (Gemini, HF, LangSmith)
â”œâ”€â”€ requirements.txt            # Dependency manifest
â””â”€â”€ submit_job.sh               # SLURM job submission script
